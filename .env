# 推理模式配置：local(本地) 或 server(服务器)
INFERENCE_MODE=local

# 本地模型路径
LOCAL_MODEL_PATH=./backend/models/

# 服务器推理API配置
SERVER_API_URL=http://localhost:8866/predict

# 文件上传配置
UPLOAD_FOLDER=./backend/static/uploads
MAX_CONTENT_LENGTH=16777216  # 16MB

# Flask配置
SECRET_KEY=your-secret-key-here